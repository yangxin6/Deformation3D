GENERAL:
  task: train  # train, test
  manual_seed: 123
  model_dir: model/hais/hais.py
  dataset_dir: data/corn_inst.py

DATA:
  data_root: dataset
  dataset: corn
  data_dir: corn/hais_test/
#  data_dir: corn/20230828_exp_v2_1_vega_1000_151_bottom_c_p/hais_1000
  filename_suffix: pth
  meta: meta_v2_1_1000/test.txt

  classes: 2
  ignore_label: -100
  class_weight: [15.43, 1.0]
  input_channel: 3
  scale: 300   # voxel_size = 1 / scale, scale 50 -> voxel_size 0.02m
  batch_size: 100
  full_scale: [128, 512]
  max_npoint: 20480
  mode: 4 # 4=mean

STRUCTURE:
  model_name: hais
  width: 32
  block_residual: True
  block_reps: 2
  use_coords: True

TRAIN:
  epochs: 500
  train_workers: 20 # data loader workers
  optim: Adam # Adam or SGD
  lr: 0.0001
  step_epoch: 200
  multiplier: 0.5
  momentum: 0.9
  weight_decay: 0.0001
  save_freq: 16  # also eval_freq
  loss_weight: [1.0, 1.0, 1.0, 1.0] # semantic_loss, offset_norm_loss, score_loss, mask_loss
  fg_thresh: 1.
  bg_thresh: 0.
  score_scale: 300 # the minimal voxel size is 2cm
  score_fullscale: 20
  score_mode: 4 # mean
  pretrain_path:
  pretrain_module: []
  fix_module: []


  point_aggr_radius: 0.01
  cluster_shift_meanActive: 300
  prepare_epochs: 100

  cal_iou_based_on_mask: True
  cal_iou_based_on_mask_start_epoch: 200

  use_mask_filter_score_feature: True
  use_mask_filter_score_feature_start_epoch: 200
  mask_filter_score_feature_thre: 0.5

  using_set_aggr_in_training: False
  using_set_aggr_in_testing: True

  max_proposal_num: 200

TEST:
  split: test
  test_epoch: 500
  test_workers: 24
  test_seed: 567

  using_NMS: True
  TEST_NMS_THRESH: 0.3
  TEST_SCORE_THRESH: 0.09
  TEST_NPOINT_THRESH: 100

  eval: True
  save_semantic: True
  save_pt_offsets: True
  save_instance: True
  single_eval: True

  test_mask_score_thre: -0.5 # bias fg << bg


  



